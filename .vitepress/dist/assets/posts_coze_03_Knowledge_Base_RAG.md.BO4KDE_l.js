import{_ as a,o as n,c as i,ag as t}from"./chunks/framework.CbQjVMS6.js";const k=JSON.parse('{"title":"Coze 零基础精通系列 03：知识库 (Knowledge Base) —— 给 AI 装上“私有大脑”","description":"","frontmatter":{},"headers":[],"relativePath":"posts/coze/03_Knowledge_Base_RAG.md","filePath":"posts/coze/03_Knowledge_Base_RAG.md"}'),e={name:"posts/coze/03_Knowledge_Base_RAG.md"};function l(o,s,r,p,h,g){return n(),i("div",null,[...s[0]||(s[0]=[t(`<h1 id="coze-零基础精通系列-03-知识库-knowledge-base-——-给-ai-装上-私有大脑" tabindex="-1">Coze 零基础精通系列 03：知识库 (Knowledge Base) —— 给 AI 装上“私有大脑” <a class="header-anchor" href="#coze-零基础精通系列-03-知识库-knowledge-base-——-给-ai-装上-私有大脑" aria-label="Permalink to &quot;Coze 零基础精通系列 03：知识库 (Knowledge Base) —— 给 AI 装上“私有大脑”&quot;">​</a></h1><blockquote><p><strong>上一篇回顾</strong>：本系列已介绍如何用结构化提示词（Prompt）约束 AI 的行为。<br><strong>本篇目标</strong>：让 AI 学会它原本不知道的知识（如公司文档、个人简历）。</p></blockquote><hr><h2 id="_1-为什么-ai-会-一本正经胡说八道" tabindex="-1">1. 为什么 AI 会“一本正经胡说八道”？ <a class="header-anchor" href="#_1-为什么-ai-会-一本正经胡说八道" aria-label="Permalink to &quot;1. 为什么 AI 会“一本正经胡说八道”？&quot;">​</a></h2><p>大模型（LLM）的训练数据是截止到过去的公开互联网数据。若询问：</p><blockquote><p>“这一期 Coze 教程的第三篇文章讲了什么？” AI 大概率会瞎编，因为它根本没看过本地电脑。</p></blockquote><p>要解决这个问题，不能把大脑拆了重练（太贵），而是要给它配一个 <strong>外挂硬盘</strong> —— 这就是 <strong>知识库</strong>。 在技术圈，这叫 <strong>RAG (Retrieval-Augmented Generation，检索增强生成)</strong>。</p><h2 id="_2-核心原理-rag-是如何工作的" tabindex="-1">2. 核心原理：RAG 是如何工作的？ <a class="header-anchor" href="#_2-核心原理-rag-是如何工作的" aria-label="Permalink to &quot;2. 核心原理：RAG 是如何工作的？&quot;">​</a></h2><p>别被缩写吓跑，RAG 的原理就是一个 <strong>“开卷考试”</strong> 的过程。</p><p>想象一下，老师（用户）问了一个超纲问题，学生（AI）不会做。但是学生手里有一本教科书（知识库）。</p><ol><li><strong>检索 (Retrieval)</strong>：学生先翻书，找到相关的段落。</li><li><strong>增强 (Augmented)</strong>：学生把书里的段落抄到脑子里，结合问题一起思考。</li><li><strong>生成 (Generation)</strong>：学生组织语言，回答老师的问题。</li></ol><p>计算机内部处理流程如下：</p><div class="language-mermaid vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">mermaid</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">graph TD</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    User([&quot;用户提问: &#39;公司几点打卡?&#39;&quot;]) --&gt; Embedding_Query[问题向量化]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    subgraph Knowledge_Base [知识库构建阶段]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        Doc[&quot;私有文档 (PDF/Word/URL)&quot;] --&gt; Split[&quot;文档分段 (切片)&quot;]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        Split --&gt; Embedding_Doc[内容向量化]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        Embedding_Doc --&gt; VectorDB[(向量数据库)]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    end</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    Embedding_Query --&gt;|计算相似度| VectorDB</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    VectorDB --&gt;|Top K 召回| Chunks[&quot;找到最相关的片段: &#39;早9晚6...&#39;&quot;]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    Chunks --&gt; FinalPrompt[组合 Prompt]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    User --&gt; FinalPrompt</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    subgraph LLM_Process [LLM 生成阶段]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        FinalPrompt -- &quot;如果是: 你是客服... 已知信息: 早9晚6... 问题: 几点打卡? 请回答&quot; --&gt; LLM</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        LLM --&gt; Answer([&quot;最终答案: &#39;您好，我们是早9晚6。&#39;&quot;])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    end</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    style VectorDB fill:#fff9c4,stroke:#fbc02d</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    style LLM fill:#e1f5fe,stroke:#01579b</span></span></code></pre></div><h3 id="关键概念通俗版" tabindex="-1">关键概念通俗版： <a class="header-anchor" href="#关键概念通俗版" aria-label="Permalink to &quot;关键概念通俗版：&quot;">​</a></h3><ul><li><strong>切片 (Chunking)</strong>：AI 一次吃不下太长的文章，所以要把文档切成一小段一小段的（比如 500 字一段）。</li><li><strong>向量化 (Embedding)</strong>：计算机不认识字，只认识数学。它把“苹果”变成一组数字 <code>[0.1, 0.9, ...]</code>。 <ul><li>“香蕉”的数字离“苹果”很近。</li><li>“卡车”的数字离“苹果”很远。</li><li>所以当你搜“水果”，它能找到“苹果”和“香蕉”，这就是 <strong>语义搜索</strong>。</li></ul></li></ul><blockquote><p>💡 <strong>知识库类型对比</strong>：</p><ul><li><strong>文本知识库 (Text)</strong>：适合非结构化文档（PDF、Word、SOP 手册）。原理是 RAG 切片。</li><li><strong>表格知识库 (Table)</strong>：适合结构化数据（价格表、员工花名册、库存表）。可以直接上传 Excel，Bot 会尝试用 SQL 精准查询，准确率远高于文本检索。</li></ul></blockquote><h2 id="_3-实战案例-打造-专属简历问答助手" tabindex="-1">3. 实战案例：打造“专属简历问答助手” <a class="header-anchor" href="#_3-实战案例-打造-专属简历问答助手" aria-label="Permalink to &quot;3. 实战案例：打造“专属简历问答助手”&quot;">​</a></h2><p>以求职场景为例，如果希望做一个 Bot，发给 HR，让 HR 直接问 Bot，而不是看枯燥的 PDF。</p><h3 id="第一步-准备粮草-数据" tabindex="-1">第一步：准备粮草（数据） <a class="header-anchor" href="#第一步-准备粮草-数据" aria-label="Permalink to &quot;第一步：准备粮草（数据）&quot;">​</a></h3><p>找一份简历（PDF 或 Markdown 格式），或者写一段自我介绍。</p><h3 id="第二步-创建知识库" tabindex="-1">第二步：创建知识库 <a class="header-anchor" href="#第二步-创建知识库" aria-label="Permalink to &quot;第二步：创建知识库&quot;">​</a></h3><ol><li>在 Coze 首页顶部导航栏点击 <strong>“知识库” (Knowledge)</strong>。</li><li>点击 <strong>“创建知识库”</strong>，选 <strong>文本格式</strong>。</li><li>上传简历文件。</li><li><strong>清洗与分段</strong>：Coze 会自动分段。可以点开看看，如果切得太碎，把一些连贯的段落手动合并（一般默认自动即可）。</li><li>等待状态变为 <strong>“启用中”</strong>。</li></ol><blockquote><p>💡 <strong>进阶技巧</strong>：知识库创建完成后，建议进行 <strong>“命中测试” (Retrieval Testing)</strong>。在设置页面的测试窗口输入几个问题，检查 AI 能否召回正确的段落。如果搜不到，可能需要调整切片规则或增加文档密度。</p></blockquote><h3 id="第三步-给-bot-装上外挂" tabindex="-1">第三步：给 Bot 装上外挂 <a class="header-anchor" href="#第三步-给-bot-装上外挂" aria-label="Permalink to &quot;第三步：给 Bot 装上外挂&quot;">​</a></h3><ol><li>回到之前创建的（或者新建一个）Bot。</li><li>在中间的 <strong>“知识库”</strong> 区域，点击 <code>+</code> 号。</li><li>选择刚才创建的 <code>我的简历库</code>。</li><li><strong>调整 Prompt</strong>： 在提示词里加上一句引导：<div class="language-markdown vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">markdown</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-light-font-weight:bold;--shiki-dark:#79B8FF;--shiki-dark-font-weight:bold;"># Skills</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">你拥有我的详细简历信息。当用户询问关于我的经历时，请必须优先搜索知识库中的内容来回答，不要编造。</span></span></code></pre></div></li></ol><h3 id="第四步-查看效果" tabindex="-1">第四步：查看效果 <a class="header-anchor" href="#第四步-查看效果" aria-label="Permalink to &quot;第四步：查看效果&quot;">​</a></h3><p>在右侧预览区提问：</p><blockquote><p>“这个候选人做过什么项目？” “他的教育背景如何？”</p></blockquote><p>你会发现，Bot 不再是瞎编乱造，而是精准地引用了简历里的原话，甚至还会帮忙总结高光时刻！</p><hr><h2 id="总结" tabindex="-1">总结 <a class="header-anchor" href="#总结" aria-label="Permalink to &quot;总结&quot;">​</a></h2><p>知识库是 Coze 最强大的功能之一。它让通用的 AI 变成了<strong>懂业务、懂用户</strong>的 AI。</p><ul><li><strong>上传</strong>文档。</li><li><strong>自动切片</strong>与向量化。</li><li>Bot <strong>自动检索</strong>并回答。</li></ul><p>基本功能的实现并不复杂。但为了实现自动发邮件、自动写周报等功能，需要更强大的工具。 下一篇，将解锁 AI 的“手脚” —— <strong>工作流 (Workflow)</strong>，这才是 Coze 真正拉开差距的杀手锏。</p>`,34)])])}const c=a(e,[["render",l]]);export{k as __pageData,c as default};
